{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from data import get_data_from_mat\n",
    "from pandas import DataFrame\n",
    "import scipy.misc as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas\n",
    "import numpy\n",
    "from algos import process_data_by_classification_and_set, convert_data_to_dict_of_array, LogisticRegression, NeuralNetwork\n",
    "seaborn.set(style='darkgrid')\n",
    "seaborn.set_context('notebook')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-vs-All logistic regression multi-class classification\n",
    "# Feedforward Neural Network simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting data and setting training set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_lenth = 4000\n",
    "\n",
    "original_data = get_data_from_mat('ex3data1.mat')\n",
    "initial_weights_data = get_data_from_mat('ex3weights.mat')\n",
    "x_data = DataFrame(original_data['X'])\n",
    "y_data = DataFrame(original_data['y'])\n",
    "y_data.columns = ['y']\n",
    "xy_data_df = pandas.concat([x_data, y_data], axis='columns')\n",
    "data_store_dictionary = process_data_by_classification_and_set(xy_data_df, training_set_lenth)\n",
    "input_data_dictionary = convert_data_to_dict_of_array(data_store_dictionary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dictionary['regularized_lambda'] = 0.0\n",
    "input_data_dictionary['number_of_iteration'] = 1000\n",
    "input_data_dictionary['learning_rate'] = 1\n",
    "input_data_dictionary['no_of_training_batches'] = 4\n",
    "input_data_dictionary['layer_structure'] = {1: 400, 2: 25, 3: 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_regression = LogisticRegression(**input_data_dictionary)\n",
    "logit_regression.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_regression.training_predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dictionary['training_y_variables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_regression.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_number(class_number):\n",
    "    if class_number >= 6:\n",
    "        return 1\n",
    "    elif class_number <= 5:\n",
    "        return 0\n",
    "    \n",
    "def get_column_number(class_number):\n",
    "    map_class = {1: 0, 6: 0, 2: 1, 7: 1, 3: 2, 8: 2, 4: 3, 9: 3, 5: 4, 10: 4}\n",
    "    return map_class[class_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(15, 10))\n",
    "for class_, iteration_chart in logit_regression.iteration_cost_df_by_class.items():\n",
    "    axes[get_row_number(class_), get_column_number(class_)].set_title('Class ' + str(class_))\n",
    "    axes[get_row_number(class_), get_column_number(class_)].plot(iteration_chart['No_of_iteration'], iteration_chart['cost'])\n",
    "    axes[get_row_number(class_), get_column_number(class_)].set_ylim([0, 1])\n",
    "    axes[get_row_number(class_), get_column_number(class_)].set_yticks(numpy.arange(0, 1, step=0.1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_weights = initial_weights_data['Theta1']\n",
    "second_layer_weights = initial_weights_data['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_ones(array):\n",
    "    # array with shape (number of datapoints, number of features)\n",
    "    bias_term_array = numpy.ones((array.shape[0], 1))\n",
    "    \n",
    "    return numpy.append(array[:, ::-1], bias_term_array, axis=1)[:, ::-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_training_x = add_bias_ones(input_data_dictionary['training_x_variables'])\n",
    "nn_testing_x = add_bias_ones(input_data_dictionary['testing_x_variables'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_layer_activation_values = 1 / (1 + numpy.exp(-nn_training_x.dot(input_layer_weights.T))) # Each row representing 25 activation values for 25 neruons in the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_layer_activation_values = add_bias_ones(second_layer_activation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer_activation_values = 1 / (1 + numpy.exp(-second_layer_activation_values.dot(second_layer_weights.T)))\n",
    "# Each row representing the probability of each column classification of those 4000 datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_predicted_traing_y = output_layer_activation_values.argmax(axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_training_accuracy = numpy.sum(nn_predicted_traing_y == input_data_dictionary['training_y_variables']) / len(input_data_dictionary['training_y_variables'])\n",
    "print(\"Neural Network Training Accuracy: \" + str(nn_training_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dictionary['learning_rate'] = 0.5\n",
    "input_data_dictionary['no_of_training_batches'] = 100\n",
    "input_data_dictionary['regularized_lambda'] = 0.000\n",
    "input_data_dictionary['number_of_iteration'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(**input_data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training accuracy: 0.78775\n",
      "Epoch 2 training accuracy: 0.86675\n",
      "Epoch 3 training accuracy: 0.89025\n",
      "Epoch 4 training accuracy: 0.902\n",
      "Epoch 5 training accuracy: 0.91525\n",
      "Epoch 6 training accuracy: 0.9205\n",
      "Epoch 7 training accuracy: 0.924\n",
      "Epoch 8 training accuracy: 0.92875\n",
      "Epoch 9 training accuracy: 0.93175\n",
      "Epoch 10 training accuracy: 0.9345\n",
      "Epoch 11 training accuracy: 0.9375\n",
      "Epoch 12 training accuracy: 0.94025\n",
      "Epoch 13 training accuracy: 0.942\n",
      "Epoch 14 training accuracy: 0.9435\n",
      "Epoch 15 training accuracy: 0.94375\n",
      "Epoch 16 training accuracy: 0.94675\n",
      "Epoch 17 training accuracy: 0.948\n",
      "Epoch 18 training accuracy: 0.94875\n",
      "Epoch 19 training accuracy: 0.95025\n",
      "Epoch 20 training accuracy: 0.95175\n",
      "Epoch 21 training accuracy: 0.953\n",
      "Epoch 22 training accuracy: 0.95375\n",
      "Epoch 23 training accuracy: 0.95475\n",
      "Epoch 24 training accuracy: 0.9555\n",
      "Epoch 25 training accuracy: 0.9575\n",
      "Epoch 26 training accuracy: 0.95825\n",
      "Epoch 27 training accuracy: 0.959\n",
      "Epoch 28 training accuracy: 0.9595\n",
      "Epoch 29 training accuracy: 0.96\n",
      "Epoch 30 training accuracy: 0.96025\n",
      "Epoch 31 training accuracy: 0.96025\n",
      "Epoch 32 training accuracy: 0.96125\n",
      "Epoch 33 training accuracy: 0.96225\n",
      "Epoch 34 training accuracy: 0.963\n",
      "Epoch 35 training accuracy: 0.96325\n",
      "Epoch 36 training accuracy: 0.96375\n",
      "Epoch 37 training accuracy: 0.96425\n",
      "Epoch 38 training accuracy: 0.96525\n",
      "Epoch 39 training accuracy: 0.9655\n",
      "Epoch 40 training accuracy: 0.9665\n",
      "Epoch 41 training accuracy: 0.96775\n",
      "Epoch 42 training accuracy: 0.96825\n",
      "Epoch 43 training accuracy: 0.9685\n",
      "Epoch 44 training accuracy: 0.9685\n",
      "Epoch 45 training accuracy: 0.96875\n",
      "Epoch 46 training accuracy: 0.96875\n",
      "Epoch 47 training accuracy: 0.9685\n",
      "Epoch 48 training accuracy: 0.969\n",
      "Epoch 49 training accuracy: 0.9695\n",
      "Epoch 50 training accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "nn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.912\n"
     ]
    }
   ],
   "source": [
    "nn.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
